model:
  target: bert.models.diffusion.DiffusionEngine
  params:
    scale_factor: 0.18215
    disable_first_stage_autocast: True
    ckpt_path: pretrained_models/checkpoints/interpolation.pt
    bad_model_path: pretrained_models/checkpoints/interpolation_bad.pt

    denoiser_config:
      target: bert.modules.diffusionmodules.denoiser.KarrasTemporalMultiDiffusion
      params:
        scaling_config:
          target: bert.modules.diffusionmodules.denoiser_scaling.VScalingWithEDMcNoise

    # network_wrapper: bert.modules.diffusionmodules.wrappers.IdentityWrapper
    network_wrapper: 
      target: bert.modules.diffusionmodules.wrappers.InterpolationWrapper
      params:
        im_size: [512, 512] # USER: adapt this to your dataset
        n_channels: 4
        starting_mask_method: zeros

    bad_model_config: null

    network_config:
      target: bert.modules.diffusionmodules.video_model.VideoUNet
      params:
        adm_in_channels: 0
        num_classes: sequential
        use_checkpoint: True
        in_channels: 9
        out_channels: 4
        model_channels: 320
        attention_resolutions: [4, 2, 1]
        num_res_blocks: 2
        channel_mult: [1, 2, 4, 4]
        num_head_channels: 64
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 1024
        spatial_transformer_attn_type: softmax-xformers
        extra_ff_mix_layer: True
        use_spatial_context: True
        merge_strategy: learned_with_images
        video_kernel_size: [3, 1, 1]
        fine_tuning_method: null
        audio_cond_method: both_keyframes
        additional_audio_frames: 0
        audio_dim: 1024
        unfreeze_blocks: ["input"] # Because we changed the input block
        # adapter_kwargs:
        #   down_ratio: 5
        #   adapter_type: null
        #   adapter_weight: null
        #   act_layer: gelu
        #   zero_init_last: True
        #   use_bias: True
        #   adapt_on_time: False
        #   condition_on: space
        #   condition_dim: 1280

    conditioner_config:
      target: bert.modules.GeneralConditioner
      params:
        emb_models:
        # - is_trainable: False
        #   input_key: cond_frames_without_noise
        #   target: bert.modules.encoders.modules.FrozenOpenCLIPImagePredictionEmbedder
        #   params:
        #     n_cond_frames: 2
        #     n_copies: 1
        #     open_clip_embedding_config:
        #       target: bert.modules.encoders.modules.FrozenOpenCLIPImageEmbedder
        #       params:
        #         freeze: True

        # - input_key: fps_id
        #   is_trainable: False
        #   target: bert.modules.encoders.modules.ConcatTimestepEmbedderND
        #   params:
        #     outdim: 256

        # - input_key: motion_bucket_id
        #   is_trainable: False
        #   target: bert.modules.encoders.modules.ConcatTimestepEmbedderND
        #   params:
        #     outdim: 256

        - input_key: cond_frames
          is_trainable: False
          target: bert.modules.encoders.modules.VideoPredictionEmbedderWithEncoder
          params:
            disable_encoder_autocast: True
            n_cond_frames: 2
            n_copies: 1
            is_ae: True
            encoder_config:
              target: bert.models.autoencoder.AutoencoderKLModeOnly
              params:
                embed_dim: 4
                monitor: val/rec_loss
                ddconfig:
                  attn_type: vanilla-xformers
                  double_z: True
                  z_channels: 4
                  resolution: 256
                  in_channels: 3
                  out_ch: 3
                  ch: 128
                  ch_mult: [1, 2, 4, 4]
                  num_res_blocks: 2
                  attn_resolutions: []
                  dropout: 0.0
                lossconfig:
                  target: torch.nn.Identity

        # - input_key: cond_aug
        #   is_trainable: False
        #   target: bert.modules.encoders.modules.ConcatTimestepEmbedderND
        #   params:
        #     outdim: 256

        - input_key: audio_emb
          is_trainable: True
          target: bert.modules.encoders.modules.WhisperAudioEmbedder
          params:
            merge_method: mean 
            linear_dim: 1024
            cond_type: crossattn
            audio_dim: 1536

    first_stage_config:
      target: bert.models.autoencoder.AutoencodingEngine
      params:
        loss_config:
          target: torch.nn.Identity
        regularizer_config:
          target: bert.modules.autoencoding.regularizers.DiagonalGaussianRegularizer
        encoder_config: 
          target: bert.modules.diffusionmodules.model.Encoder
          params:
            attn_type: vanilla
            double_z: True
            z_channels: 4
            resolution: 256
            in_channels: 3
            out_ch: 3
            ch: 128
            ch_mult: [1, 2, 4, 4]
            num_res_blocks: 2
            attn_resolutions: []
            dropout: 0.0
        decoder_config:
          target: bert.modules.autoencoding.temporal_ae.VideoDecoder
          params:
            attn_type: vanilla
            double_z: True
            z_channels: 4
            resolution: 256
            in_channels: 3
            out_ch: 3
            ch: 128
            ch_mult: [1, 2, 4, 4]
            num_res_blocks: 2
            attn_resolutions: []
            dropout: 0.0
            video_kernel_size: [3, 1, 1]

    sampler_config:
      target: bert.modules.diffusionmodules.sampling.EulerEDMSampler
      params:
        num_steps: 10
        discretization_config:
          target: bert.modules.diffusionmodules.discretizer.AYSDiscretization
          # params:
            # sigma_max: 700.0

        # guider_config:
        #   target: bert.modules.diffusionmodules.guiders.LinearPredictionGuider
        #   params:
        #     max_scale: 2.5
        #     min_scale: 1.0
        #     num_frames: 14

        guider_config:
          target: bert.modules.diffusionmodules.guiders.KarrasGuider
          params:
            scale: 2.0
            # num_frames: 14
          # target: bert.modules.diffusionmodules.guiders.MultipleCondVanilla
          # params:
          #   scales: [1., 0.5]
          #   condition_names: [[cond_frames, cond_frames_without_noise], audio_emb]

        # guider_config:
        #   target: bert.modules.diffusionmodules.guiders.TrianglePredictionGuider
        #   params:
        #     max_scale: 2.5
        #     min_scale: 1.0
        #     num_frames: 14
        #     period: [1,1]
        #     period_fusing: multiply

   